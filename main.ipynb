{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('sources')\n",
    "import traceback\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2219f1-125f-428e-ae72-bb5af44e7cdd",
   "metadata": {},
   "source": [
    "# Choose the test\n",
    "All the test available are in folder 'CPIs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cd6ff0-611f-4554-bec2-4a5ffcd06bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_name = \"test5\" #choice-task-init-reverse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cea916-6e05-41d1-82b8-db2c0286966e",
   "metadata": {},
   "source": [
    "## Load File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616698ac2fa9d9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpi_file_path = f'CPIs/{process_name}.cpi'\n",
    "\n",
    "print(f\"Loading CPI file: {cpi_file_path}\")\n",
    "\n",
    "try:\n",
    "\twith open(cpi_file_path, 'r') as f:\n",
    "\t\tcpi_dict = json.load(f)\n",
    "\n",
    "\tprint(\"✓ CPI file loaded successfully!\")\n",
    "\tprint(f\"Root region type: {cpi_dict['type']}\")\n",
    "\tprint(f\"Root region ID: {cpi_dict['id']}\")\n",
    "\n",
    "\t# Pretty print the CPI structure\n",
    "\tprint(\"\\nCPI Structure:\")\n",
    "\tprint(\"=\" * 50)\n",
    "\tprint(json.dumps(cpi_dict, indent=2))\n",
    "\n",
    "except FileNotFoundError:\n",
    "\tprint(f\"❌ File not found: {cpi_file_path}\")\n",
    "\tprint(\"Available files in CPIs directory:\")\n",
    "\ttry:\n",
    "\t\tfor f in os.listdir('CPIs'):\n",
    "\t\t\tif f.endswith('.cpi'):\n",
    "\t\t\t\tprint(f\"  - {f}\")\n",
    "\texcept:\n",
    "\t\tprint(\"  Could not list CPIs directory\")\n",
    "except Exception as e:\n",
    "\tprint(f\"❌ Error loading CPI file: {e}\")\n",
    "\ttraceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ed26b5-d5ae-4f61-91f1-9b1f20041f02",
   "metadata": {},
   "source": [
    "# FROM CPI TO SPIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8fe918cc1cc060",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cpi_to_mdp.cpitospin import analyze_cpi_structure, CPIToSPINConverter\n",
    "\n",
    "print(\"\\nCPI Structure Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "if 'cpi_dict' in locals():\n",
    "\tanalyze_cpi_structure(cpi_dict)\n",
    "\n",
    "print(\"Converting CPI to SPIN...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "\tconverter = CPIToSPINConverter()\n",
    "\tspin_model = converter.convert_cpi_to_spin(cpi_dict)\n",
    "\n",
    "\tprint(\"✓ Conversion successful!\")\n",
    "\tprint(\"\\nSPIN Model Summary:\")\n",
    "\tprint(\"-\" * 30)\n",
    "\tspin_model.print_model_summary()\n",
    "\n",
    "except Exception as e:\n",
    "\tprint(f\"❌ Conversion failed: {e}\")\n",
    "\ttraceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b581cbb167050363",
   "metadata": {},
   "source": [
    "## Process Visualization\n",
    "\n",
    "The CPI dictionary can be visualized as a directed graph to better understand its structure. In this visualization:\n",
    "\n",
    "- **Task nodes** show duration and impact values (cost, time, quality)\n",
    "- **Nature nodes** display their probability values (e.g., \"p=0.7\")\n",
    "- **Sequence nodes** connect components with \"head\" and \"tail\" edges\n",
    "- **Parallel nodes** show concurrent branches with \"first\" and \"second\" edges\n",
    "- **Choice nodes** represent decision points with \"true\" and \"false\" branches\n",
    "\n",
    "Each node type is represented as a box, with edges showing the relationships between components. This hierarchical representation helps understand the process flow and decision points in the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b6e669a6daa12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cpi_to_mdp.cpitospin import create_cpi_visualization, create_spin_visualization\n",
    "\n",
    "print(\"\\nCreating visualizations...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "\t# Create CPI visualization\n",
    "\tcpi_viz = create_cpi_visualization(cpi_dict, \"CPI: Loop Example\")\n",
    "\tprint(\"✓ CPI visualization created\")\n",
    "\n",
    "\t# Create SPIN visualization\n",
    "\tspin_viz = create_spin_visualization(spin_model, \"SPIN: Loop Example\")\n",
    "\tprint(\"✓ SPIN visualization created\")\n",
    "\n",
    "\t# Display visualizations (if in Jupyter)\n",
    "\ttry:\n",
    "\t\tprint(\"\\nCPI Structure Visualization:\")\n",
    "\t\tdisplay(cpi_viz)\n",
    "\n",
    "\t\tprint(\"\\nSPIN Model Visualization:\")\n",
    "\t\tdisplay(spin_viz)\n",
    "\texcept NameError:\n",
    "\t\t# Not in Jupyter, save to files instead\n",
    "\t\tprint(\"Saving visualizations to files...\")\n",
    "\n",
    "\t\t# Save CPI visualization\n",
    "\t\tcpi_output = process_name + '_cpi'\n",
    "\t\tcpi_viz.render(cpi_output, cleanup=True)\n",
    "\t\tprint(f\"CPI visualization saved to: {cpi_output}.png\")\n",
    "\n",
    "\t\t# Save SPIN visualization\n",
    "\t\tspin_output = process_name + '_spin'\n",
    "\t\tspin_viz.render(spin_output, cleanup=True)\n",
    "\t\tprint(f\"SPIN visualization saved to: {spin_output}.png\")\n",
    "\n",
    "except Exception as e:\n",
    "\tprint(f\"❌ Visualization failed: {e}\")\n",
    "\ttraceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856e60bc-8310-4544-822d-6a9feb506970",
   "metadata": {},
   "source": [
    "# FROM SPIN TO PRISM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4c7462785fdf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nGenerating PRISM model...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "\tprism_model = spin_model.generate_prism_model()\n",
    "\n",
    "\tprint(\"✓ PRISM model generated successfully!\")\n",
    "\n",
    "\t# Show model statistics\n",
    "\tlines = prism_model.split('\\n')\n",
    "\twords = prism_model.split()\n",
    "\n",
    "\tprint(f\"Model statistics:\")\n",
    "\tprint(f\"  Lines: {len(lines)}\")\n",
    "\tprint(f\"  Words: {len(words)}\")\n",
    "\tprint(f\"  Characters: {len(prism_model)}\")\n",
    "\n",
    "\t# Show first 20 lines\n",
    "\tprint(f\"\\nFirst 20 lines of PRISM model:\")\n",
    "\tprint(\"-\" * 40)\n",
    "\tfor i, line in enumerate(lines[:20]):\n",
    "\t\tprint(f\"{i + 1:2d}: {line}\")\n",
    "\n",
    "\tif len(lines) > 20:\n",
    "\t\tprint(f\"... ({len(lines) - 20} more lines)\")\n",
    "\n",
    "except Exception as e:\n",
    "\tprint(f\"❌ PRISM generation failed: {e}\")\n",
    "\ttraceback.print_exc()\n",
    "\n",
    "print(\"\\nSaving PRISM model...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "\toutput_file =  \"models/\" + process_name + '.nm'\n",
    "\twith open(output_file, 'w') as f:\n",
    "\t\tf.write(prism_model)\n",
    "\n",
    "\tprint(f\"✓ PRISM model saved to: {output_file}\")\n",
    "\n",
    "\t# Verify file was created\n",
    "\tif os.path.exists(output_file):\n",
    "\t\tfile_size = os.path.getsize(output_file)\n",
    "\t\tprint(f\"File size: {file_size} bytes\")\n",
    "\telse:\n",
    "\t\tprint(\"❌ Warning: File was not created\")\n",
    "\n",
    "except Exception as e:\n",
    "\tprint(f\"❌ Save failed: {e}\")\n",
    "\ttraceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dd67e1-ba42-4146-8739-73cf144f26f3",
   "metadata": {},
   "source": [
    "## RUN PRISM ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b55b74-f829-4f86-949e-8aca5dbd066d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!prism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2414348c-8ef5-4ed3-963d-f3b47aa6db7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from env import PRISM_PATH\n",
    "from prism import run_prism_analysis\n",
    "\n",
    "prism_path = None # If PRISM_PATH is set in the environment\n",
    "#prism_path = PRISM_PATH\n",
    "run_prism_analysis(process_name, create_mdp=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb471fe-6da0-415c-9dcc-347ae4469034",
   "metadata": {},
   "source": [
    "### Read output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b1da85-8f93-4981-90d3-f47c4dcc1fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Source\n",
    "\n",
    "dot_filename = f\"models/{process_name}.dot\"\n",
    "\n",
    "with open(dot_filename, 'r', encoding='utf-8') as f: #{process_name}/{process_name}.dot\n",
    "    dot_content = f.read()\n",
    "    Source(dot_content).render(filename=f\"models/{process_name}\", format='svg', cleanup=True)\n",
    "\n",
    "states_filenames = f\"models/{process_name}_states.csv\"\n",
    "transitions_filenames = f\"models/{process_name}_trans.tra\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc73186-040b-4e15-9dd5-16cbe91a1bed",
   "metadata": {},
   "source": [
    "# FROM PRISM TO MDP\n",
    "\n",
    "Since PRISM models are based on an extended form of MDPs, we now provide the compact version of the MDP generated by PRISM, which corresponds to the equivalent SPIN model. This enhances clarity and facilitates easier comparison between the two representations.\n",
    "\n",
    "CASE 1: deterministic, 2 states directly connected\n",
    "\n",
    "CASE 2: time passage 2 states connected with label=\"{{∅}}\" fillcolor=lightsalmon\n",
    "\n",
    "Case 3: choice: red transition with internal writing some choice I take (1+) and saying true/false --> written in the next state\n",
    "\n",
    "case 4 natural: as choice but green transition and label on the probability arcs\n",
    "\n",
    "Case 5: nature and contemporary choice: double transition first choice and then nature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbde089-7f09-437b-978a-aba7b7bccdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Source\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def get_compact_states(states: pd.DataFrame, transitions: pd.DataFrame):\n",
    "    states['STAGE'] = states['(STAGE'].apply(\n",
    "        lambda x: x.split(':')[-1].split('(')[-1] if isinstance(x, str) else x\n",
    "    )\n",
    "    states.drop(columns=['(STAGE'], inplace=True)\n",
    "\n",
    "    paren_cols = [col for col in states.columns if col.endswith(')')]\n",
    "    \n",
    "    for col in paren_cols:\n",
    "        states[col.replace(')', '')] = states[col].apply(\n",
    "            lambda x: x[-2] if isinstance(x, str) and len(x) >= 2 else x\n",
    "        )\n",
    "        states.drop(columns=[col], inplace=True)\n",
    "\n",
    "    states = states.apply(pd.to_numeric)\n",
    "\n",
    "    update_cols = [col for col in states.columns if col.endswith('_update')]\n",
    "    state_cols = [col for col in states.columns if col.endswith('_state')]\n",
    "    value_cols = [col for col in states.columns if col.endswith('_value')]  \n",
    "\n",
    "    stage_mask = states['STAGE'].isin([0])    \n",
    "    update_mask = (states[update_cols] == 0).all(axis=1)    \n",
    "    state_mask = (states[state_cols] == 0).all(axis=1)\n",
    "    new_states_df = states[stage_mask & update_mask & state_mask]\n",
    "    return new_states_df, set(new_states_df.index.astype(int).tolist()), value_cols\n",
    "\n",
    "def prepare_label_states_dot(name:int =0, parts = {}):\n",
    "    joined_parts = ''\n",
    "    for k, v in parts.items():\n",
    "        joined_parts += f'{k} → {v} \\n'\n",
    "    return f'{name} [label=\"{joined_parts}\", style=\"filled\", fillcolor=\"lightblue\"];'\n",
    "def format_label(row, value_cols):\n",
    "    parts = {}\n",
    "    '''\n",
    "    {\n",
    "        col.replace('_value', ''): [\n",
    "                             int(row[col]), # valore temporale\n",
    "                             1 if choice and true in col elif 0 if choice and false  else  None #mi segno se choice e in quale ramo\n",
    "                             1 if nature and true in col else 0 #mi segno se nature e in quale ramo\n",
    "                                    ]\n",
    "        \n",
    "    }\n",
    "    '''\n",
    "    for col in value_cols:\n",
    "        if row[col] >= 0:\n",
    "            parts[col.replace('_value', '')] = int(row[col])\n",
    "    return prepare_label_states_dot(row.name, parts), parts\n",
    "\n",
    "def create_trans_dict(transitions:pd.DataFrame, verbose = False):\n",
    "    trans = transitions[0].str.split(expand=True)\n",
    "    if verbose:\n",
    "        print(trans.head())\n",
    "        print(trans.shape)\n",
    "    has_prob = trans.shape[1] >= 5\n",
    "    \n",
    "    # Extract relevant columns\n",
    "    if has_prob:\n",
    "        source_dest = trans[[0, 2, 3, 4]]\n",
    "        source_dest.columns = ['source', 'destination', 'prob', 'label']\n",
    "    else:\n",
    "        source_dest = trans[[0, 2, 3]]\n",
    "        source_dest.columns = ['source', 'destination', 'label']\n",
    "    trans_dict = defaultdict(list)\n",
    "    \n",
    "    for _, row in source_dest.iterrows():\n",
    "        source = int(row['source'])\n",
    "        destination = int(row['destination'])\n",
    "        prob = float(row['prob']) if has_prob else 1.0  # Default prob to 1.0 if missing\n",
    "        label = [row['label'] ]if row['label'] else []\n",
    "        trans_dict[source].append((destination, prob,label))\n",
    "    \n",
    "    return dict(trans_dict)\n",
    "\n",
    "def find_next_state(src:int, trans_dict:dict, possible_targets: set, verbose = False):  \n",
    "        res = []\n",
    "        for i in range(len(trans_dict[src])):\n",
    "            if src == trans_dict[src][i][0]:\n",
    "                return [] # it's final \n",
    "            if trans_dict[src][i][0] in possible_targets:\n",
    "                if verbose:\n",
    "                    print(trans_dict[src][i][0], trans_dict[src][i][1])\n",
    "                res.append(trans_dict[src][i]) # questo significa che src e target sono collegati direttamente \n",
    "            \n",
    "        if len(res) > 0:\n",
    "            return res\n",
    "        for i in range(len(trans_dict[src])): \n",
    "            # continua a cercare ma la destinazione è diventata source\n",
    "            l = trans_dict[src][i][2]\n",
    "            for r in find_next_state( trans_dict[src][i][0], trans_dict, possible_targets):\n",
    "                l.extend(r[2])\n",
    "                res.append((r[0], round(r[1] * trans_dict[src][i][1], 3), l))            \n",
    "        return res\n",
    "\n",
    "def parse_rewards_file(filepath):\n",
    "    rewards_dict = defaultdict(dict)\n",
    "    current_impact = None\n",
    "\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            \n",
    "            if line.startswith('rewards'):\n",
    "                match = re.search(r'rewards\\s+\"([^\"]+)\"', line)\n",
    "                if match:\n",
    "                    current_impact = match.group(1)\n",
    "\n",
    "            elif line == 'endrewards':\n",
    "                current_impact = None\n",
    "\n",
    "            elif current_impact:\n",
    "                match = re.match(r'\\[([^\\]]+)\\]\\s+true\\s*:\\s*([0-9.eE+-]+);', line)\n",
    "                \n",
    "                if match:\n",
    "                    task_name = match.group(1)\n",
    "                    value = float(match.group(2))\n",
    "                    rewards_dict[task_name][current_impact] = value\n",
    "\n",
    "    return dict(rewards_dict)\n",
    "\n",
    "def format_label_impacts_impactslabel(label: list, rewards_dict: dict):\n",
    "    l = []\n",
    "    impact_sums = {}  # Accumulate sums for each impact\n",
    "    \n",
    "    for col in label:\n",
    "        l.append(f\"{col.replace('fire_', '')}\")\n",
    "        for impact, value in rewards_dict[col].items():\n",
    "            print(label)\n",
    "            if impact in impact_sums:\n",
    "                impact_sums[impact] += value\n",
    "            else:\n",
    "                impact_sums[impact] = value\n",
    "\n",
    "    # Format summed impacts as \"impact_name:total_value\"\n",
    "    lab_impacts = [f'{impact}:{value}' for impact, value in impact_sums.items()]\n",
    "    return '\\n'.join(l), '\\n'.join(lab_impacts)\n",
    "    \n",
    "def create_states_mdp(states:pd.DataFrame, transitions:pd.DataFrame, process_name = 'test0', save =False):\n",
    "    \n",
    "    new_states_df, possible_targets, value_cols = get_compact_states(states, transitions)\n",
    "    trans_dict = create_trans_dict(transitions)\n",
    "    rewards_dict = parse_rewards_file(f\"models/{process_name}.nm\")\n",
    "    lines = ['digraph LTS {', 'node [label=\"\", shape=\"box\"];']\n",
    "    # print(new_states_df)\n",
    "    idx_trans = max(possible_targets)+1 \n",
    "    rows= dict(new_states_df.iterrows())\n",
    "    for idx, row in rows.items():\n",
    "        place_name_dot, place_name = format_label(row, value_cols)\n",
    "        lines.append(place_name_dot) # add node states\n",
    "        targets = find_next_state(idx, trans_dict, possible_targets)        \n",
    "        if len(targets) == 1:\n",
    "            # case 1 or case 2\n",
    "            next_idx_target, _, label = targets[0]\n",
    "            _, place_name_next = format_label(rows[next_idx_target], value_cols)\n",
    "            if label: # add tasks and impacts \n",
    "                l , lab_impacts = format_label_impacts_impactslabel(label, rewards_dict)\n",
    "                label_node_id = f'label_{idx_trans}'\n",
    "                lines.append(f'{label_node_id} [label=\"{l} \\\\n {lab_impacts}\", shape=\"box\", style=\"filled,dashed\", fillcolor=\"lightgrey\"];')\n",
    "                lines.append(f'{idx} -> {label_node_id} [style=\"dotted\"];')\n",
    "            print(place_name, 'place name', )\n",
    "            print(place_name_next, 'place name next', )\n",
    "            def is_passing_time(place_name, place_name_next):\n",
    "                for k, v in place_name_next.items():\n",
    "                    if k in place_name.keys():\n",
    "                        if place_name[k] < v:\n",
    "                            return True # if passing time \n",
    "                return False # if not passing time\n",
    "            if is_passing_time(place_name, place_name_next):\n",
    "                # Case 2\n",
    "                lines.append(f'{idx_trans} [label=\"{{∅}}\" , style=\"filled\", fillcolor=\"lightsalmon\", shape=\"circle\"];')      \n",
    "                lines.append(f'{idx} -> {idx_trans};')\n",
    "                lines.append(f'{idx_trans} -> {next_idx_target}; ')\n",
    "            else:\n",
    "                # Case 1              \n",
    "                lines.append(f'{idx} -> {next_idx_target};')\n",
    "        else: \n",
    "            pass\n",
    "            # for t in targets:\n",
    "            #     next_idx, probability, label = t\n",
    "            #     prob_label = f'[label = \"\"]'     \n",
    "            #     _, place_name_next = format_label(next_row, value_cols)\n",
    "            #     if 'choice' in place_name_next  and probability == 1.0 and 'nature' not in place_name_next:\n",
    "            #         # Case 3: only choices\n",
    "            #         lines.append(f'{idx_trans} [label=\"{{{place_name_next}}}\" , style=\"filled\", fillcolor=\"lightcoral\", shape=\"circle\" ];')\n",
    "            #         lines.append(f'{idx} -> {idx_trans};')\n",
    "            #         lines.append(f'{idx_trans} -> {next_idx} {prob_label}; ')\n",
    "            #     elif 'nature' in place_name_next and probability < 1.0 and 'choice' not in place_name_next:\n",
    "            #         # Case 4: only natures\n",
    "            #         prob_label = f'[label = \"{probability}\"]'\n",
    "            #         lines.append(f'{idx_trans} [label=\"{{{place_name_next}}}\" , style=\"filled\", fillcolor=\"lightgreen\", shape=\"circle\" ];')\n",
    "            #         lines.append(f'{idx} -> {idx_trans};')\n",
    "            #         lines.append(f'{idx_trans} -> {next_idx} {prob_label}; ')\n",
    "            #     else:\n",
    "            #         # Case 5: natures and choices\n",
    "            #         idx_nature = f'{idx_trans*25}'\n",
    "            #         lines.append(f'{idx_trans} [label=\"{{{place_name_next}}}\" , style=\"filled\", fillcolor=\"lightcoral\", shape=\"circle\" ];')\n",
    "            #         lines.append(f'{idx_nature} [label=\"{{{place_name_next}}}\" , style=\"filled\", fillcolor=\"lightgreen\", shape=\"circle\" ];')\n",
    "            #         lines.append(f'{idx} -> {idx_trans};')\n",
    "            #         lines.append(f'{idx_trans} -> {idx_nature};')\n",
    "            #         prob_label = f'[label = \"{probability}\"]'                    \n",
    "                    # lines.append(f'{idx_nature} -> {next_idx} {prob_label}; ')\n",
    "\n",
    "                    # idx -> idx_choice -> idx_nat -> idx_next\n",
    "        idx_trans +=1\n",
    "    lines.append('}')\n",
    "    compress_dot = \"\\n\".join(lines)\n",
    "    if save:\n",
    "        Source(compressed_dot).render(filename=f\"models/{process_name}_cleaned\", format='svg', cleanup=True)\n",
    "    return compress_dot\n",
    "\n",
    "\n",
    "states = pd.read_csv(states_filenames)\n",
    "transitions = pd.read_csv(transitions_filenames, skiprows=1, header= None)\n",
    "\n",
    "compressed_dot = create_states_mdp(states, transitions, process_name)\n",
    "\n",
    "#print(compressed_dot)\n",
    "Source(compressed_dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d4dee3-5ba2-4e97-bf8e-a0283f0f4864",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compressed_dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c60ab9-5901-47c3-907c-72d1942b56b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78af8a2e-594b-4f08-b2cf-d825571e71cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
