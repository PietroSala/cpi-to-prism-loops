{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {},
   "source": [
    "import sys\n",
    "sys.path.append('sources')\n",
    "import traceback\n",
    "import os\n",
    "import json"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8d2219f1-125f-428e-ae72-bb5af44e7cdd",
   "metadata": {},
   "source": [
    "# Choose the test\n",
    "All the test available are in folder 'CPIs'"
   ]
  },
  {
   "cell_type": "code",
   "id": "e1cd6ff0-611f-4554-bec2-4a5ffcd06bca",
   "metadata": {},
   "source": [
    "process_name = \"test0\" #choice-task-init-reverse"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d8cea916-6e05-41d1-82b8-db2c0286966e",
   "metadata": {},
   "source": [
    "## Load File "
   ]
  },
  {
   "cell_type": "code",
   "id": "616698ac2fa9d9dd",
   "metadata": {},
   "source": [
    "cpi_file_path = f'CPIs/{process_name}.cpi'\n",
    "\n",
    "print(f\"Loading CPI file: {cpi_file_path}\")\n",
    "\n",
    "try:\n",
    "\twith open(cpi_file_path, 'r') as f:\n",
    "\t\tcpi_dict = json.load(f)\n",
    "\n",
    "\tprint(\"✓ CPI file loaded successfully!\")\n",
    "\tprint(f\"Root region type: {cpi_dict['type']}\")\n",
    "\tprint(f\"Root region ID: {cpi_dict['id']}\")\n",
    "\n",
    "\t# Pretty print the CPI structure\n",
    "\tprint(\"\\nCPI Structure:\")\n",
    "\tprint(\"=\" * 50)\n",
    "\tprint(json.dumps(cpi_dict, indent=2))\n",
    "\n",
    "except FileNotFoundError:\n",
    "\tprint(f\"❌ File not found: {cpi_file_path}\")\n",
    "\tprint(\"Available files in CPIs directory:\")\n",
    "\ttry:\n",
    "\t\tfor f in os.listdir('CPIs'):\n",
    "\t\t\tif f.endswith('.cpi'):\n",
    "\t\t\t\tprint(f\"  - {f}\")\n",
    "\texcept:\n",
    "\t\tprint(\"  Could not list CPIs directory\")\n",
    "except Exception as e:\n",
    "\tprint(f\"❌ Error loading CPI file: {e}\")\n",
    "\ttraceback.print_exc()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f5ed26b5-d5ae-4f61-91f1-9b1f20041f02",
   "metadata": {},
   "source": [
    "# FROM CPI TO SPIN"
   ]
  },
  {
   "cell_type": "code",
   "id": "5b8fe918cc1cc060",
   "metadata": {},
   "source": [
    "from cpi_to_mdp.cpitospin import analyze_cpi_structure, CPIToSPINConverter\n",
    "\n",
    "print(\"\\nCPI Structure Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "if 'cpi_dict' in locals():\n",
    "\tanalyze_cpi_structure(cpi_dict)\n",
    "\n",
    "print(\"Converting CPI to SPIN...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "\tconverter = CPIToSPINConverter()\n",
    "\tspin_model = converter.convert_cpi_to_spin(cpi_dict)\n",
    "\n",
    "\tprint(\"✓ Conversion successful!\")\n",
    "\tprint(\"\\nSPIN Model Summary:\")\n",
    "\tprint(\"-\" * 30)\n",
    "\tspin_model.print_model_summary()\n",
    "\n",
    "except Exception as e:\n",
    "\tprint(f\"❌ Conversion failed: {e}\")\n",
    "\ttraceback.print_exc()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b581cbb167050363",
   "metadata": {},
   "source": [
    "## Process Visualization\n",
    "\n",
    "The CPI dictionary can be visualized as a directed graph to better understand its structure. In this visualization:\n",
    "\n",
    "- **Task nodes** show duration and impact values (cost, time, quality)\n",
    "- **Nature nodes** display their probability values (e.g., \"p=0.7\")\n",
    "- **Sequence nodes** connect components with \"head\" and \"tail\" edges\n",
    "- **Parallel nodes** show concurrent branches with \"first\" and \"second\" edges\n",
    "- **Choice nodes** represent decision points with \"true\" and \"false\" branches\n",
    "\n",
    "Each node type is represented as a box, with edges showing the relationships between components. This hierarchical representation helps understand the process flow and decision points in the system."
   ]
  },
  {
   "cell_type": "code",
   "id": "73b6e669a6daa12a",
   "metadata": {},
   "source": [
    "from cpi_to_mdp.cpitospin import create_cpi_visualization, create_spin_visualization\n",
    "\n",
    "print(\"\\nCreating visualizations...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "\t# Create CPI visualization\n",
    "\tcpi_viz = create_cpi_visualization(cpi_dict, \"CPI: Loop Example\")\n",
    "\tprint(\"✓ CPI visualization created\")\n",
    "\n",
    "\t# Create SPIN visualization\n",
    "\tspin_viz = create_spin_visualization(spin_model, \"SPIN: Loop Example\")\n",
    "\tprint(\"✓ SPIN visualization created\")\n",
    "\n",
    "\t# Display visualizations (if in Jupyter)\n",
    "\ttry:\n",
    "\t\tprint(\"\\nCPI Structure Visualization:\")\n",
    "\t\tdisplay(cpi_viz)\n",
    "\n",
    "\t\tprint(\"\\nSPIN Model Visualization:\")\n",
    "\t\tdisplay(spin_viz)\n",
    "\texcept NameError:\n",
    "\t\t# Not in Jupyter, save to files instead\n",
    "\t\tprint(\"Saving visualizations to files...\")\n",
    "\n",
    "\t\t# Save CPI visualization\n",
    "\t\tcpi_output = process_name + '_cpi'\n",
    "\t\tcpi_viz.render(cpi_output, cleanup=True)\n",
    "\t\tprint(f\"CPI visualization saved to: {cpi_output}.png\")\n",
    "\n",
    "\t\t# Save SPIN visualization\n",
    "\t\tspin_output = process_name + '_spin'\n",
    "\t\tspin_viz.render(spin_output, cleanup=True)\n",
    "\t\tprint(f\"SPIN visualization saved to: {spin_output}.png\")\n",
    "\n",
    "except Exception as e:\n",
    "\tprint(f\"❌ Visualization failed: {e}\")\n",
    "\ttraceback.print_exc()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "856e60bc-8310-4544-822d-6a9feb506970",
   "metadata": {},
   "source": [
    "# FROM SPIN TO PRISM"
   ]
  },
  {
   "cell_type": "code",
   "id": "9e4c7462785fdf8e",
   "metadata": {},
   "source": [
    "print(\"\\nGenerating PRISM model...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "\tprism_model = spin_model.generate_prism_model()\n",
    "\n",
    "\tprint(\"✓ PRISM model generated successfully!\")\n",
    "\n",
    "\t# Show model statistics\n",
    "\tlines = prism_model.split('\\n')\n",
    "\twords = prism_model.split()\n",
    "\n",
    "\tprint(f\"Model statistics:\")\n",
    "\tprint(f\"  Lines: {len(lines)}\")\n",
    "\tprint(f\"  Words: {len(words)}\")\n",
    "\tprint(f\"  Characters: {len(prism_model)}\")\n",
    "\n",
    "\t# Show first 20 lines\n",
    "\tprint(f\"\\nFirst 20 lines of PRISM model:\")\n",
    "\tprint(\"-\" * 40)\n",
    "\tfor i, line in enumerate(lines[:20]):\n",
    "\t\tprint(f\"{i + 1:2d}: {line}\")\n",
    "\n",
    "\tif len(lines) > 20:\n",
    "\t\tprint(f\"... ({len(lines) - 20} more lines)\")\n",
    "\n",
    "except Exception as e:\n",
    "\tprint(f\"❌ PRISM generation failed: {e}\")\n",
    "\ttraceback.print_exc()\n",
    "\n",
    "print(\"\\nSaving PRISM model...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "\toutput_file =  \"models/\" + process_name + '.nm'\n",
    "\twith open(output_file, 'w') as f:\n",
    "\t\tf.write(prism_model)\n",
    "\n",
    "\tprint(f\"✓ PRISM model saved to: {output_file}\")\n",
    "\n",
    "\t# Verify file was created\n",
    "\tif os.path.exists(output_file):\n",
    "\t\tfile_size = os.path.getsize(output_file)\n",
    "\t\tprint(f\"File size: {file_size} bytes\")\n",
    "\telse:\n",
    "\t\tprint(\"❌ Warning: File was not created\")\n",
    "\n",
    "except Exception as e:\n",
    "\tprint(f\"❌ Save failed: {e}\")\n",
    "\ttraceback.print_exc()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e5dd67e1-ba42-4146-8739-73cf144f26f3",
   "metadata": {},
   "source": [
    "## RUN PRISM ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "id": "b9b55b74-f829-4f86-949e-8aca5dbd066d",
   "metadata": {},
   "source": [
    "!prism"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2414348c-8ef5-4ed3-963d-f3b47aa6db7d",
   "metadata": {},
   "source": [
    "from env import PRISM_PATH\n",
    "from prism import run_prism_analysis\n",
    "\n",
    "prism_path = None # If PRISM_PATH is set in the environment\n",
    "#prism_path = PRISM_PATH\n",
    "run_prism_analysis(process_name, prism_path=prism_path, create_mdp=True)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2fb471fe-6da0-415c-9dcc-347ae4469034",
   "metadata": {},
   "source": [
    "### Read output"
   ]
  },
  {
   "cell_type": "code",
   "id": "41b1da85-8f93-4981-90d3-f47c4dcc1fab",
   "metadata": {},
   "source": [
    "from graphviz import Source\n",
    "\n",
    "dot_filename = f\"models/{process_name}.dot\"\n",
    "\n",
    "with open(dot_filename, 'r', encoding='utf-8') as f: #{process_name}/{process_name}.dot\n",
    "    dot_content = f.read()\n",
    "    Source(dot_content).render(filename=f\"models/{process_name}\", format='svg', cleanup=True)\n",
    "\n",
    "states_filenames = f\"models/{process_name}_states.csv\"\n",
    "transitions_filenames = f\"models/{process_name}_trans.tra\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1dc73186-040b-4e15-9dd5-16cbe91a1bed",
   "metadata": {},
   "source": [
    "# FROM PRISM TO MDP\n",
    "\n",
    "Since PRISM models are based on an extended form of MDPs, we now provide the compact version of the MDP generated by PRISM, which corresponds to the equivalent SPIN model. This enhances clarity and facilitates easier comparison between the two representations."
   ]
  },
  {
   "cell_type": "code",
   "id": "1fbde089-7f09-437b-978a-aba7b7bccdd2",
   "metadata": {},
   "source": [
    "from graphviz import Source\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "def create_states_mdp(states, transitions):\n",
    "    states['STAGE'] = states['(STAGE'].apply(lambda x: x.split(':')[-1].split('(')[-1] if isinstance(x, str) else x)\n",
    "    states.drop(columns=['(STAGE'], inplace=True)\n",
    "\n",
    "    paren_cols = [col for col in states.columns if col.endswith(')')]\n",
    "    for col in paren_cols:\n",
    "        states[col.replace(')', '')] = states[col].apply(lambda x: x[-2] if isinstance(x, str) and len(x) >= 2 else x)\n",
    "        states.drop(columns=[col], inplace=True)\n",
    "\n",
    "    states = states.apply(pd.to_numeric)\n",
    "\n",
    "    # Select relevant columns\n",
    "    update_cols = [col for col in states.columns if col.endswith('_update')]\n",
    "    state_cols = [col for col in states.columns if col.endswith('_state')]\n",
    "    value_cols = [col for col in states.columns if col.endswith('_value')]\n",
    "\n",
    "    # Identify new states\n",
    "    stage_mask = states['STAGE'].isin([0])\n",
    "    update_mask = (states[update_cols] == 0).all(axis=1)\n",
    "    state_mask = (states[state_cols] == 0).all(axis=1)\n",
    "    new_states_df = states[stage_mask & update_mask & state_mask]\n",
    "    new_state_ids = new_states_df.index.astype(int).tolist() \n",
    "    new_state_set = set(new_state_ids) #set([int(nid) for nid in new_state_ids if nid not in nodes_to_remove])\n",
    "\n",
    "    lines = ['digraph LTS {', 'node [label=\"\", shape=\"box\"];']\n",
    "\n",
    "    def format_label(row):\n",
    "        parts = [\n",
    "            f\"{col.replace('_value', '')} → {int(row[col])}\"\n",
    "            for col in value_cols if row[col] >= 0\n",
    "        ]\n",
    "        return f'{row.name} [label=\"{row.name}\\\\n(' + \", \".join(parts) + ')\", style=\"filled\", fillcolor=\"lightblue\"];' # fillcolor=\"#FF0000\"\n",
    "\n",
    "    \n",
    "    trans = transitions[0].str.split(expand=True)\n",
    "    print(trans.head())\n",
    "    print(trans.shape)\n",
    "    # Check if 'prob' column exists (based on column count)\n",
    "    has_prob = trans.shape[1] >= 5\n",
    "    \n",
    "    # Extract relevant columns\n",
    "    if has_prob:\n",
    "        source_dest = trans[[0, 2, 3, 4]]\n",
    "        source_dest.columns = ['source', 'destination', 'prob', 'label']\n",
    "    else:\n",
    "        source_dest = trans[[0, 2, 3]]\n",
    "        source_dest.columns = ['source', 'destination', 'label']\n",
    "    # Create dictionary: {source: [(destination, prob)]} or {source: [(destination,)]}\n",
    "    trans_dict = defaultdict(list)\n",
    "    \n",
    "    for _, row in source_dest.iterrows():\n",
    "        source = int(row['source'])\n",
    "        destination = int(row['destination'])\n",
    "        prob = float(row['prob']) if has_prob else 1.0  # Default prob to 1.0 if missing\n",
    "        label = [row['label'] ]if row['label'] else []\n",
    "        trans_dict[source].append((destination, prob,label))\n",
    "    \n",
    "    # Optional: convert to regular dict\n",
    "    trans_dict = dict(trans_dict)\n",
    "    def find_next_state(src:int, trans_dict:dict, possible_targets):  \n",
    "        res = []\n",
    "        for i in range(len(trans_dict[src])):\n",
    "            if src == trans_dict[src][i][0]:\n",
    "                return [] # it's final \n",
    "            if trans_dict[src][i][0] in possible_targets:\n",
    "                # print(trans_dict[src][i][0], trans_dict[src][i][1])\n",
    "                res.append(trans_dict[src][i]) # questo significa che src e target sono collegati direttamente \n",
    "            \n",
    "        if len(res) > 0:\n",
    "            return res\n",
    "        for i in range(len(trans_dict[src])): \n",
    "            # continua a cercare ma la destinazione è diventata source\n",
    "            l = trans_dict[src][i][2]\n",
    "            for r in find_next_state( trans_dict[src][i][0], trans_dict, possible_targets):\n",
    "                l.extend(r[2])\n",
    "                res.append((r[0], round(r[1] * trans_dict[src][i][1], 3), l))\n",
    "            \n",
    "        return res\n",
    "    idx_trans = max(new_state_ids)+1    \n",
    "    for idx, row in new_states_df.iterrows():\n",
    "        # if str(idx) not in nodes_to_remove:\n",
    "        lab = format_label(row)\n",
    "        lines.append(lab) \n",
    "        targets = find_next_state(idx, trans_dict, new_state_set)\n",
    "        for t in targets:\n",
    "            next_idx, probability, label = t\n",
    "            prob_label = f'[label = \"\"]'\n",
    "            if probability < 1.0:\n",
    "                prob_label = f'[label = \"{probability}\"]'\n",
    "            if label and probability < 1.0:\n",
    "                lines.append(f'{idx_trans} [label=\"{label} \" , style=\"filled\", fillcolor=\"green\", shape=\"circle\" ];')\n",
    "            elif label:\n",
    "                lines.append(f'{idx_trans} [label=\"{label} \" , style=\"filled\", fillcolor=\"salmon\", shape=\"circle\" ];')\n",
    "            else:\n",
    "                lines.append(f'{idx_trans} [label=\"∅\" , style=\"filled\", fillcolor=\"firebrick3\", shape=\"circle\"];')         \n",
    "            \n",
    "            lines.append(f'{idx} -> {idx_trans};')\n",
    "            lines.append(f'{idx_trans} -> {next_idx} {prob_label}; ')\n",
    "            idx_trans +=1\n",
    "    lines.append('}')\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "states = pd.read_csv(states_filenames)\n",
    "transitions = pd.read_csv(transitions_filenames, skiprows=1, header= None)\n",
    "\n",
    "compressed_dot = create_states_mdp(states, transitions)\n",
    "\n",
    "#print(compressed_dot)\n",
    "Source(compressed_dot).render(filename=f\"models/{process_name}_cleaned\", format='svg', cleanup=True)\n",
    "Source(compressed_dot)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "78c60ab9-5901-47c3-907c-72d1942b56b5",
   "metadata": {},
   "source": [
    "states"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "78af8a2e-594b-4f08-b2cf-d825571e71cd",
   "metadata": {},
   "source": [
    "transitions"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
